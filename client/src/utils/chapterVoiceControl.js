import { useRef, useEffect, useState } from 'react';
import { useNavigate } from 'react-router-dom';

const VoiceControlChapter = ({ chapters, storyId, onRead, onStop, onContinue, nextId, previousId , navigateToChapter}) => {
  const navigate = useNavigate();
  const recognitionRef = useRef(null);
  const [isListening, setIsListening] = useState(false);
  const processingRef = useRef(false);

  // LÆ°u trá»¯ giÃ¡ trá»‹ má»›i nháº¥t cá»§a nextId vÃ  previousId báº±ng useRef
  const nextIdRef = useRef(nextId);
  const previousIdRef = useRef(previousId);
  const onContinueRef = useRef(onContinue);
  const onReadRef = useRef(onRead);
  const onStopRef = useRef(onStop);

  // Cáº­p nháº­t ref má»—i khi props thay Ä‘á»•i
  useEffect(() => {
    nextIdRef.current = nextId;
    previousIdRef.current = previousId;
    onContinueRef.current = onContinue;
    onReadRef.current = onRead;
    onStopRef.current = onStop;
    console.log("Props cáº­p nháº­t - previousId:", previousId, "nextId:", nextId);
  }, [nextId, previousId]);

  useEffect(() => {
    if (!window.SpeechRecognition && !window.webkitSpeechRecognition) {
      console.log("TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ Web Speech API");
      return;
    }

    if (!recognitionRef.current) {
      const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = "vi-VN";
      recognition.continuous = true;
      recognition.interimResults = false;

      recognition.onresult = (event) => {
        const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
        console.log("Nghe Ä‘Æ°á»£c:", transcript);
        console.log("previousId hiá»‡n táº¡i:", previousIdRef.current);
        console.log("nextId hiá»‡n táº¡i:", nextIdRef.current);

        if (processingRef.current) return;
        processingRef.current = true;
        setTimeout(() => (processingRef.current = false), 1000);

        if (transcript.includes("táº­p") && previousIdRef.current) {
          console.log("Äiá»u hÆ°á»›ng Ä‘áº¿n chÆ°Æ¡ng trÆ°á»›c:", previousIdRef.current);
          navigateToChapter(previousIdRef.current);
        } else if (transcript.includes("tiáº¿p theo") && nextIdRef.current) {
          console.log("Äiá»u hÆ°á»›ng Ä‘áº¿n chÆ°Æ¡ng tiáº¿p theo:", nextIdRef.current);
          navigateToChapter(nextIdRef.current);
        } else if (transcript.includes("nghe truyá»‡n")) {
          onReadRef.current();
        } else if (transcript.includes("dá»«ng nghe")) {
          onStopRef.current();
        } else if (transcript.includes("nghe tiáº¿p")) {
          console.log("Gá»i onContinue vá»›i lastReadingIndex:");
          onContinueRef.current();
        } else {
          chapters.forEach(chap => {
            if (transcript.includes(chap.name.toLowerCase())) {
              navigate(`/stories/${storyId}/chapters/${chap.id}`);
            }
          });
        }
      };

      recognitionRef.current = recognition;
    }
  }, [chapters, storyId, navigate, onRead, onStop, onContinue]);

  useEffect(() => {
    const handleKeyDown = (event) => {
      if (event.ctrlKey && recognitionRef.current && !isListening) {
        recognitionRef.current.start();
        setIsListening(true);
        console.log("ðŸŽ¤ Mic báº­t");
      }
    };

    const handleKeyUp = (event) => {
      if (!event.ctrlKey && recognitionRef.current && isListening) {
        recognitionRef.current.stop();
        setIsListening(false);
        console.log("ðŸ”‡ Mic táº¯t");
      }
    };

    window.addEventListener("keydown", handleKeyDown);
    window.addEventListener("keyup", handleKeyUp);

    return () => {
      window.removeEventListener("keydown", handleKeyDown);
      window.removeEventListener("keyup", handleKeyUp);
    };
  }, [isListening]);

  return null;
};

export default VoiceControlChapter;