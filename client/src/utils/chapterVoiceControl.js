import { useRef, useEffect, useState } from 'react';
import { useNavigate } from 'react-router-dom';
import axios from 'axios';

const VoiceControlChapter = ({ chapters, storyId, onRead, onStop, onContinue, nextId, previousId, isDataReady }) => {
  const navigate = useNavigate();
  const recognitionRef = useRef(null);
  const [isListening, setIsListening] = useState(false);
  const processingRef = useRef(false);

  const nextIdRef = useRef(nextId);
  const previousIdRef = useRef(previousId);

  useEffect(() => {
    nextIdRef.current = nextId;
    previousIdRef.current = previousId;
    console.log("Props cáº­p nháº­t - previousId:", previousId, "nextId:", nextId);
  }, [nextId, previousId]);

  useEffect(() => {
    if (!window.SpeechRecognition && !window.webkitSpeechRecognition) {
      console.log("TrÃ¬nh duyá»‡t khÃ´ng há»— trá»£ Web Speech API");
      return;
    }

    if (!recognitionRef.current) {
      const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
      recognition.lang = "vi-VN";
      recognition.continuous = true;
      recognition.interimResults = false;

      recognition.onresult = (event) => {
        const transcript = event.results[event.results.length - 1][0].transcript.toLowerCase().trim();
        console.log("Nghe Ä‘Æ°á»£c:", transcript);
        console.log("previousId hiá»‡n táº¡i:", previousIdRef.current);
        console.log("nextId hiá»‡n táº¡i:", nextIdRef.current);
        console.log("isDataReady trong VoiceControlChapter:", isDataReady);

        if (processingRef.current) return;
        processingRef.current = true;
        setTimeout(() => (processingRef.current = false), 1000);

        if (transcript.includes("nghe truyá»‡n")) {
          if (!isDataReady) {
            console.warn("Dá»¯ liá»‡u chÆ°a sáºµn sÃ ng trong VoiceControlChapter");
            return;
          }
          console.log("Báº¯t Ä‘áº§u nghe truyá»‡n...");
          onRead();
        } else if (transcript.includes("dá»«ng nghe")) {
          console.log("Dá»«ng nghe truyá»‡n...");
          onStop();
        } else if (transcript.includes("nghe tiáº¿p")) {
          console.log("Tiáº¿p tá»¥c nghe truyá»‡n...");
          onContinue();
        } else if (transcript.includes("táº­p") && previousIdRef.current) {
          console.log("Äiá»u hÆ°á»›ng Ä‘áº¿n chÆ°Æ¡ng trÆ°á»›c:", previousIdRef.current);
          navigate(`/stories/${storyId}/chapters/${previousIdRef.current}`);
          window.scrollTo(0, 0);
        } else if (transcript.includes("tiáº¿p theo") && nextIdRef.current) {
          console.log("Äiá»u hÆ°á»›ng Ä‘áº¿n chÆ°Æ¡ng tiáº¿p theo:", nextIdRef.current);
          navigate(`/stories/${storyId}/chapters/${nextIdRef.current}`);
          window.scrollTo(0, 0);
        } else {
          const matchedChapter = chapters.find(chap => transcript.includes(chap.name.toLowerCase()));
          if (matchedChapter) {
            console.log("Äiá»u hÆ°á»›ng Ä‘áº¿n chÆ°Æ¡ng:", matchedChapter._id);
            navigate(`/stories/${storyId}/chapters/${matchedChapter._id}`);
          }
        }
      };

      recognitionRef.current = recognition;
    }
  }, [chapters, storyId, navigate, onRead, onStop, onContinue, isDataReady]);

  useEffect(() => {
    const handleKeyDown = (event) => {
      if (event.ctrlKey && recognitionRef.current && !isListening) {
        recognitionRef.current.start();
        setIsListening(true);
        console.log("ðŸŽ¤ Mic báº­t");
      }
    };

    const handleKeyUp = (event) => {
      if (!event.ctrlKey && recognitionRef.current && isListening) {
        recognitionRef.current.stop();
        setIsListening(false);
        console.log("ðŸ”‡ Mic táº¯t");
      }
    };

    window.addEventListener("keydown", handleKeyDown);
    window.addEventListener("keyup", handleKeyUp);

    return () => {
      window.removeEventListener("keydown", handleKeyDown);
      window.removeEventListener("keyup", handleKeyUp);
    };
  }, [isListening]);

  return null;
};

export default VoiceControlChapter;